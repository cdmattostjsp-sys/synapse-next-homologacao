# -*- coding: utf-8 -*-
"""
utils/integration_etp.py ‚Äì Exporta√ß√£o/Importa√ß√£o do ETP
Respons√°vel por:
- Gravar o arquivo exports/etp_data.json a partir dos metadados do ETP.
- Ler o arquivo exports/etp_data.json para pr√©-preencher o m√≥dulo TR.
"""

import json
import os
import re
from typing import Dict, Any
from pathlib import Path
from utils.ai_client import AIClient

# ==========================================================
# üìÇ Diret√≥rios e caminhos de exporta√ß√£o
# ==========================================================
EXPORTS_DIR = os.path.join(os.path.dirname(os.path.dirname(__file__)), "exports")
ETP_JSON_PATH = os.path.join(EXPORTS_DIR, "etp_data.json")
client = AIClient()

# ==========================================================
# üì§ Fun√ß√µes utilit√°rias
# ==========================================================
def ensure_exports_dir(path: str = EXPORTS_DIR) -> None:
    os.makedirs(path, exist_ok=True)

def export_etp_to_json(data: Dict[str, Any], path: str = ETP_JSON_PATH) -> str:
    ensure_exports_dir(os.path.dirname(path))
    with open(path, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)
    return path

def load_etp_from_json(path: str = ETP_JSON_PATH) -> Dict[str, Any]:
    try:
        if os.path.exists(path):
            with open(path, "r", encoding="utf-8") as f:
                return json.load(f)
    except Exception:
        pass
    return {}

# ==========================================================
# üß† Base de conhecimento institucional (ETP)
# ==========================================================
def ler_modelos_etp() -> str:
    """L√™ a base de conhecimento institucional (Knowledge Base) para ETP."""
    base = Path(__file__).resolve().parents[1] / "knowledge" / "etp_models"
    textos = []
    if base.exists():
        for arq in base.glob("*.txt"):
            try:
                textos.append(arq.read_text(encoding="utf-8"))
            except Exception:
                pass
    return "\n\n".join(textos)

# ==========================================================
# ü§ñ Processamento de Insumo ‚Äì ETP
# ==========================================================
def processar_insumo_etp(arquivo, artefato: str = "ETP") -> dict:
    """
    Extrai o texto do arquivo enviado (PDF, DOCX ou TXT),
    realiza an√°lise sem√¢ntica institucional e retorna campos estruturados.
    """
    from io import BytesIO
    import fitz, docx2txt

    dados = arquivo.read()
    arquivo.seek(0)
    nome = arquivo.name.lower()
    texto_extraido = ""

    # 1Ô∏è‚É£ Extra√ß√£o de texto
    try:
        if nome.endswith(".pdf"):
            pdf = fitz.open(stream=dados, filetype="pdf")
            texto_extraido = "".join(p.get_text() for p in pdf)
        elif nome.endswith(".docx"):
            texto_extraido = docx2txt.process(BytesIO(dados))
        elif nome.endswith(".txt"):
            texto_extraido = dados.decode("utf-8", errors="ignore")
    except Exception as e:
        return {"erro": f"Falha ao extrair texto: {e}"}

    if not texto_extraido.strip():
        return {"erro": "Texto vazio ap√≥s leitura do insumo."}

    texto_limpo = re.sub(r"\s+", " ", texto_extraido).strip()
    modelos = ler_modelos_etp()

    # 2Ô∏è‚É£ Prompt institucional
    system_prompt = (
        "Voc√™ √© um agente institucional especializado em Estudo T√©cnico Preliminar (ETP). "
        "Analise o texto do insumo e extraia os campos padronizados conforme o modelo do TJSP."
    )

    user_prompt = f"""
Texto do insumo:
\"\"\"{texto_limpo}\"\"\"

Modelos institucionais de refer√™ncia:
\"\"\"{modelos}\"\"\"

Retorne apenas um JSON com os seguintes campos:
- objeto
- problema_a_resolver
- solucao_proposta
- alternativas_analisadas
- justificativa_da_escolha
- resultados_esperados
- impacto_orcamentario
"""

    # 3Ô∏è‚É£ Chamada √† IA institucional
    try:
        response = client.chat([
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt}
        ])
        conteudo = response["content"]
        match = re.search(r"\{.*\}", conteudo, re.DOTALL)
        campos = json.loads(match.group(0)) if match else {"objeto": texto_limpo[:800]}
    except Exception as e:
        campos = {"erro": f"Falha ao processar IA: {e}"}

    # ==========================================================
    # üîÑ Normaliza√ß√£o dos campos para compatibilidade com o front-end
    # ==========================================================
    campos_ai = {
        "requisitos": campos.get("solucao_proposta", campos.get("objeto", "")),
        "custos": campos.get("impacto_orcamentario", "A definir com base no or√ßamento institucional."),
        "riscos": campos.get("problema_a_resolver", "Sem riscos relevantes identificados."),
        "responsavel_tecnico": campos.get("responsavel_tecnico", "Respons√°vel t√©cnico a designar.")
    }

    # Garante que nenhum campo fique vazio
    for k, v in campos_ai.items():
        if not v:
            campos_ai[k] = "‚Äî"

    print(f"[IA:ETP] Arquivo: {arquivo.name} ‚Äì Campos normalizados: {list(campos_ai.keys())}")

    # ==========================================================
    # üì¶ Retorno final compat√≠vel com SynapseNext
    # ==========================================================
    return {
        "artefato": artefato,
        "nome_arquivo": arquivo.name,
        "status": "processado",
        "campos_ai": campos_ai
    }
