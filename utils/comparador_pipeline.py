# ==========================================================
# SynapseNext â€“ Fase BrasÃ­lia (Passo 10B â€“ Comparador.IA)
# ==========================================================
# MÃ³dulo de anÃ¡lise cruzada e coerÃªncia semÃ¢ntica entre os
# artefatos da fase interna (DFD â†’ ETP â†’ TR â†’ Edital)
# ==========================================================

from __future__ import annotations
from pathlib import Path
from datetime import datetime
from typing import Dict, Any, List
import json
import re
from difflib import SequenceMatcher

# ==========================================================
# ğŸ§  FunÃ§Ãµes utilitÃ¡rias
# ==========================================================

def _root() -> Path:
    return Path(__file__).resolve().parents[1]

def _ensure_dirs() -> Dict[str, Path]:
    base = _root()
    dirs = {
        "snapshots": base / "exports" / "auditoria" / "snapshots",
        "analises": base / "exports" / "analises",
    }
    for d in dirs.values():
        d.mkdir(parents=True, exist_ok=True)
    return dirs

def _load_latest_snapshot(artefato: str) -> str | None:
    """
    Retorna o conteÃºdo mais recente do snapshot Markdown do artefato informado.
    """
    dirs = _ensure_dirs()
    snaps = sorted(dirs["snapshots"].glob(f"{artefato}_*.md"), reverse=True)
    if not snaps:
        return None
    with open(snaps[0], "r", encoding="utf-8") as f:
        return f.read()

def _clean_text(text: str) -> str:
    """Limpa formataÃ§Ã£o, tÃ­tulos e espaÃ§amento."""
    text = re.sub(r"[*#>\-]+", " ", text)
    text = re.sub(r"\s+", " ", text)
    return text.strip()

def _similarity(a: str, b: str) -> float:
    """Calcula similaridade (0â€“100) entre duas strings."""
    if not a or not b:
        return 0.0
    return round(SequenceMatcher(None, a.lower(), b.lower()).ratio() * 100, 2)


# ==========================================================
# ğŸ“˜ NÃºcleo principal
# ==========================================================

def carregar_snapshots(recente: bool = True) -> Dict[str, str]:
    """
    Carrega os textos Markdown mais recentes de cada artefato.
    """
    artefatos = ["DFD", "ETP", "TR", "Edital"]
    dados = {}
    for art in artefatos:
        texto = _load_latest_snapshot(art)
        if texto:
            dados[art] = _clean_text(texto)
    return dados


def analisar_coerencia(artefatos: Dict[str, str]) -> Dict[str, Any]:
    """
    Compara os artefatos carregados e gera mÃ©tricas de coerÃªncia textual.
    """
    resultados = {"coerencia_global": 0, "comparacoes": {}, "divergencias": [], "ausencias": []}

    pares = [("DFD", "ETP"), ("ETP", "TR"), ("TR", "Edital")]
    total_sim = 0
    total_pairs = 0

    for a1, a2 in pares:
        t1, t2 = artefatos.get(a1), artefatos.get(a2)
        if not t1 or not t2:
            resultados["ausencias"].append({
                "campo": f"{a1}-{a2}",
                "descricao": f"NÃ£o hÃ¡ conteÃºdo disponÃ­vel para {a1} ou {a2}."
            })
            continue

        sim = _similarity(t1, t2)
        resultados["comparacoes"][f"{a1}-{a2}"] = sim
        total_sim += sim
        total_pairs += 1

        # Regras de alerta
        if sim < 50:
            resultados["divergencias"].append({
                "campo": f"{a1}-{a2}",
                "descricao": f"Baixa similaridade entre {a1} e {a2} ({sim}%). Pode indicar desalinhamento de informaÃ§Ãµes."
            })
        elif 50 <= sim < 75:
            resultados["divergencias"].append({
                "campo": f"{a1}-{a2}",
                "descricao": f"Similaridade parcial entre {a1} e {a2} ({sim}%). Recomenda-se revisÃ£o dos trechos de justificativa ou objeto."
            })

    if total_pairs > 0:
        resultados["coerencia_global"] = round(total_sim / total_pairs, 2)

    return resultados


# ==========================================================
# ğŸ§¾ GeraÃ§Ã£o de relatÃ³rio
# ==========================================================

def gerar_relatorio(resultados: Dict[str, Any]) -> Dict[str, str]:
    """
    Gera relatÃ³rio .json e .md com base nos resultados da anÃ¡lise de coerÃªncia.
    """
    dirs = _ensure_dirs()
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    base_name = f"relatorio_coerencia_{timestamp}"
    json_path = dirs["analises"] / f"{base_name}.json"
    md_path = dirs["analises"] / f"{base_name}.md"

    # JSON estruturado
    with open(json_path, "w", encoding="utf-8") as jf:
        json.dump(resultados, jf, indent=4, ensure_ascii=False)

    # Markdown legÃ­vel
    md = [
        "# ğŸ§© RelatÃ³rio de CoerÃªncia entre Artefatos",
        f"**Data:** {datetime.now().strftime('%d/%m/%Y %H:%M:%S')}",
        f"**CoerÃªncia Global:** {resultados.get('coerencia_global', 0)}%",
        "",
        "## ComparaÃ§Ãµes",
    ]
    for k, v in resultados.get("comparacoes", {}).items():
        md.append(f"- **{k}** â†’ Similaridade: `{v}%`")

    if resultados.get("divergencias"):
        md.append("\n## âš ï¸ DivergÃªncias")
        for d in resultados["divergencias"]:
            md.append(f"- {d['descricao']}")

    if resultados.get("ausencias"):
        md.append("\n## âŒ AusÃªncias")
        for a in resultados["ausencias"]:
            md.append(f"- {a['descricao']}")

    with open(md_path, "w", encoding="utf-8") as mf:
        mf.write("\n".join(md))

    return {
        "ok": True,
        "json_path": str(json_path),
        "md_path": str(md_path),
        "coerencia_global": resultados.get("coerencia_global", 0),
    }


# ==========================================================
# ğŸš€ ExecuÃ§Ã£o direta (teste rÃ¡pido)
# ==========================================================
if __name__ == "__main__":
    dados = carregar_snapshots()
    if not dados:
        print("âš ï¸ Nenhum snapshot encontrado em exports/auditoria/snapshots/")
    else:
        print("ğŸ§© Artefatos carregados:", list(dados.keys()))
        resultado = analisar_coerencia(dados)
        saida = gerar_relatorio(resultado)
        print(f"âœ… RelatÃ³rio salvo em: {saida['md_path']}")
