# ==========================================================
# SynapseNext â€“ Fase BrasÃ­lia (Passo 10B â€“ Comparador.IA)
# ==========================================================
# MÃ³dulo de anÃ¡lise cruzada e coerÃªncia semÃ¢ntica entre os
# artefatos da fase interna (DFD â†’ ETP â†’ TR â†’ Edital)
# ==========================================================

from __future__ import annotations
from pathlib import Path
from datetime import datetime
from typing import Dict, Any, List
import json
import re
from difflib import SequenceMatcher

# ==========================================================
# ğŸ§  FunÃ§Ãµes utilitÃ¡rias
# ==========================================================

def _root() -> Path:
    return Path(__file__).resolve().parents[1]

def _ensure_dirs() -> Dict[str, Path]:
    base = _root()
    dirs = {
        "snapshots": base / "exports" / "auditoria" / "snapshots",
        "analises": base / "exports" / "analises",
    }
    for d in dirs.values():
        d.mkdir(parents=True, exist_ok=True)
    return dirs

def _load_latest_snapshot(artefato: str) -> str | None:
    """
    Retorna o conteÃºdo mais recente do snapshot Markdown do artefato informado.
    """
    dirs = _ensure_dirs()
    snaps = sorted(dirs["snapshots"].glob(f"{artefato}_*.md"), reverse=True)
    if not snaps:
        return None
    with open(snaps[0], "r", encoding="utf-8") as f:
        return f.read()

def _clean_text(text: str) -> str:
    """Limpa formataÃ§Ã£o, tÃ­tulos e espaÃ§amento."""
    text = re.sub(r"[*#>\-]+", " ", text)
    text = re.sub(r"\s+", " ", text)
    return text.strip()

def _extract_keywords(text: str) -> set:
    """
    Extrai palavras-chave relevantes do texto (substantivos, verbos, termos tÃ©cnicos).
    Remove stopwords e normaliza termos.
    """
    # Normalizar texto
    text = text.lower()
    
    # Stopwords bÃ¡sicas do portuguÃªs
    stopwords = {
        'a', 'o', 'e', 'Ã©', 'de', 'da', 'do', 'das', 'dos', 'em', 'no', 'na', 
        'nos', 'nas', 'para', 'com', 'por', 'uma', 'um', 'os', 'as', 'ao', 'Ã ',
        'aos', 'Ã s', 'pelo', 'pela', 'pelos', 'pelas', 'que', 'se', 'ou', 'mas',
        'etc', 'ser', 'ter', 'estar', 'data', 'dia', 'mÃªs', 'ano'
    }
    
    # Extrair palavras (mÃ­nimo 3 caracteres)
    palavras = re.findall(r'\b\w{3,}\b', text)
    
    # Filtrar stopwords e criar conjunto
    keywords = {p for p in palavras if p not in stopwords}
    
    return keywords

def _similarity(a: str, b: str) -> float:
    """
    Calcula similaridade (0â€“100) entre duas strings usando:
    1. SobreposiÃ§Ã£o de palavras-chave (85% do peso) - conceitos e termos tÃ©cnicos
    2. Similaridade de sequÃªncia SequenceMatcher (15% do peso) - estrutura textual
    """
    if not a or not b:
        return 0.0
    
    # 1. AnÃ¡lise baseada em palavras-chave (mais inteligente)
    keywords_a = _extract_keywords(a)
    keywords_b = _extract_keywords(b)
    
    if not keywords_a or not keywords_b:
        # Fallback para SequenceMatcher se nÃ£o houver keywords
        return round(SequenceMatcher(None, a.lower(), b.lower()).ratio() * 100, 2)
    
    # Calcular Jaccard similarity (interseÃ§Ã£o / uniÃ£o)
    intersecao = keywords_a & keywords_b
    uniao = keywords_a | keywords_b
    jaccard_sim = (len(intersecao) / len(uniao)) * 100 if uniao else 0
    
    # 2. SequenceMatcher como complemento (detecta ordem e estrutura)
    sequence_sim = SequenceMatcher(None, a.lower(), b.lower()).ratio() * 100
    
    # Combinar mÃ©tricas: 85% keywords (conceitos), 15% sequence (estrutura)
    # Prioriza concordÃ¢ncia conceitual sobre ordem exata das palavras
    similaridade_final = (jaccard_sim * 0.85) + (sequence_sim * 0.15)
    
    return round(similaridade_final, 2)


# ==========================================================
# ğŸ“˜ NÃºcleo principal
# ==========================================================

def carregar_snapshots(recente: bool = True) -> Dict[str, str]:
    """
    Carrega os textos Markdown mais recentes de cada artefato.
    """
    artefatos = ["DFD", "ETP", "TR", "Edital"]
    dados = {}
    for art in artefatos:
        texto = _load_latest_snapshot(art)
        if texto:
            dados[art] = _clean_text(texto)
    return dados


def analisar_coerencia(artefatos: Dict[str, str]) -> Dict[str, Any]:
    """
    Compara os artefatos carregados e gera mÃ©tricas de coerÃªncia textual.
    
    VALORES ESPERADOS DE COERÃŠNCIA:
    - 60-100%: Excelente coerÃªncia (vocabulÃ¡rio muito similar)
    - 40-60%:  Boa coerÃªncia (conceitos alinhados, formulaÃ§Ã£o diferente)
    - 30-40%:  CoerÃªncia moderada (mesmo tema, diferentes nÃ­veis de detalhamento)
    - <30%:    Baixa coerÃªncia (possÃ­vel desalinhamento ou falta de contexto)
    
    OBSERVAÃ‡ÃƒO: Documentos como DFDâ†’ETPâ†’TRâ†’Edital naturalmente apresentam
    coerÃªncia moderada (35-45%) pois cada um tem propÃ³sito especÃ­fico e 
    nÃ­vel de detalhamento distinto, mesmo tratando do mesmo objeto.
    """
    resultados = {"coerencia_global": 0, "comparacoes": {}, "divergencias": [], "ausencias": []}

    pares = [("DFD", "ETP"), ("ETP", "TR"), ("TR", "Edital")]
    total_sim = 0
    total_pairs = 0

    for a1, a2 in pares:
        t1, t2 = artefatos.get(a1), artefatos.get(a2)
        if not t1 or not t2:
            resultados["ausencias"].append({
                "campo": f"{a1}-{a2}",
                "descricao": f"NÃ£o hÃ¡ conteÃºdo disponÃ­vel para {a1} ou {a2}."
            })
            continue

        sim = _similarity(t1, t2)
        resultados["comparacoes"][f"{a1}-{a2}"] = sim
        total_sim += sim
        total_pairs += 1

        # Regras de alerta ajustadas para valores realistas
        # Documentos progressivos (DFDâ†’ETPâ†’TRâ†’Edital) naturalmente tÃªm 30-45% de coerÃªncia
        if sim < 25:
            resultados["divergencias"].append({
                "campo": f"{a1}-{a2}",
                "descricao": f"ğŸ”´ CoerÃªncia muito baixa entre {a1} e {a2} ({sim}%). Recomenda-se revisar urgentemente o alinhamento de informaÃ§Ãµes, objeto e justificativa."
            })
        elif 25 <= sim < 35:
            resultados["divergencias"].append({
                "campo": f"{a1}-{a2}",
                "descricao": f"ğŸŸ¡ CoerÃªncia baixa entre {a1} e {a2} ({sim}%). Verificar se objeto, justificativa e especificaÃ§Ãµes estÃ£o alinhados entre os documentos."
            })

    if total_pairs > 0:
        resultados["coerencia_global"] = round(total_sim / total_pairs, 2)

    return resultados


# ==========================================================
# ğŸ§¾ GeraÃ§Ã£o de relatÃ³rio
# ==========================================================

def gerar_relatorio(resultados: Dict[str, Any]) -> Dict[str, str]:
    """
    Gera relatÃ³rio .json e .md com base nos resultados da anÃ¡lise de coerÃªncia.
    """
    dirs = _ensure_dirs()
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    base_name = f"relatorio_coerencia_{timestamp}"
    json_path = dirs["analises"] / f"{base_name}.json"
    md_path = dirs["analises"] / f"{base_name}.md"

    # JSON estruturado
    with open(json_path, "w", encoding="utf-8") as jf:
        json.dump(resultados, jf, indent=4, ensure_ascii=False)

    # Markdown legÃ­vel
    md = [
        "# ğŸ§© RelatÃ³rio de CoerÃªncia entre Artefatos",
        f"**Data:** {datetime.now().strftime('%d/%m/%Y %H:%M:%S')}",
        f"**CoerÃªncia Global:** {resultados.get('coerencia_global', 0)}%",
        "",
        "## ComparaÃ§Ãµes",
    ]
    for k, v in resultados.get("comparacoes", {}).items():
        md.append(f"- **{k}** â†’ Similaridade: `{v}%`")

    if resultados.get("divergencias"):
        md.append("\n## âš ï¸ DivergÃªncias")
        for d in resultados["divergencias"]:
            md.append(f"- {d['descricao']}")

    if resultados.get("ausencias"):
        md.append("\n## âŒ AusÃªncias")
        for a in resultados["ausencias"]:
            md.append(f"- {a['descricao']}")

    with open(md_path, "w", encoding="utf-8") as mf:
        mf.write("\n".join(md))

    return {
        "ok": True,
        "json_path": str(json_path),
        "md_path": str(md_path),
        "coerencia_global": resultados.get("coerencia_global", 0),
    }


# ==========================================================
# ğŸš€ ExecuÃ§Ã£o direta (teste rÃ¡pido)
# ==========================================================
if __name__ == "__main__":
    dados = carregar_snapshots()
    if not dados:
        print("âš ï¸ Nenhum snapshot encontrado em exports/auditoria/snapshots/")
    else:
        print("ğŸ§© Artefatos carregados:", list(dados.keys()))
        resultado = analisar_coerencia(dados)
        saida = gerar_relatorio(resultado)
        print(f"âœ… RelatÃ³rio salvo em: {saida['md_path']}")
