# ==========================================================
# utils/ai_client.py ‚Äî vNext_r4 (com diagn√≥stico em logs)
# SynapseNext ‚Äì Cliente Institucional OpenAI (TJSP)
# ==========================================================

from dotenv import load_dotenv
load_dotenv()

import os
import json
from openai import OpenAI


class AIClient:
    """
    Cliente institucional padronizado para uso interno dos agentes IA.
    Agora com diagn√≥stico detalhado via logs (prints no Streamlit).
    """

    def __init__(self, model: str = None):

        api_key = os.getenv("OPENAI_API_KEY")
        if not api_key:
            raise ValueError("‚ùå OPENAI_API_KEY n√£o encontrada em ambiente.")

        self.client = OpenAI(api_key=api_key)
        self.model = model or os.getenv("OPENAI_MODEL", "gpt-4o-mini")

    # ==========================================================
    # M√âTODO PRINCIPAL
    # ==========================================================
    def ask(self, prompt: str, conteudo: str | bytes = "", artefato: str = "DFD") -> dict:
        """
        Envia prompt institucional + conte√∫do de documento para o modelo
        e retorna a resposta j√° tratada (dict ou texto cru).

        Tamb√©m registra informa√ß√µes de diagn√≥stico via prints
        (vis√≠veis nos logs do Streamlit Cloud).
        """

        # ---------------------------------------------
        # Normaliza√ß√£o do conte√∫do recebido
        # ---------------------------------------------
        if isinstance(conteudo, bytes):
            conteudo = conteudo.decode("utf-8", errors="ignore")
        elif not isinstance(conteudo, str):
            conteudo = str(conteudo)

        conteudo = conteudo or ""
        trecho_documento = conteudo[:8000]  # recorte para evitar excesso de contexto

        try:
            # ======================================================
            # üî• ESTRUTURA CORRIGIDA (system + user)
            # ======================================================
            mensagens = [
                {
                    "role": "system",
                    "content": (
                        "Voc√™ √© o assistente institucional do Tribunal de Justi√ßa do Estado de S√£o Paulo (TJSP). "
                        "Sua fun√ß√£o √© gerar documentos administrativos formais (DFD, ETP, TR, Edital, Contrato) "
                        "seguindo integralmente o prompt institucional fornecido."
                    ),
                },
                {
                    "role": "user",
                    "content": (
                        f"{prompt}\n\n"
                        f"=== CONTE√öDO DO DOCUMENTO (INSUMO) ===\n"
                        f"{trecho_documento}\n\n"
                        f"=== INSTRU√á√ÉO FINAL ===\n"
                        f"Responda EXCLUSIVAMENTE em JSON v√°lido para o artefato institucional: {artefato}."
                    ),
                },
            ]

            # ======================================================
            # Chamada ao modelo (OpenAI oficial)
            # ======================================================
            resposta = self.client.chat.completions.create(
                model=self.model,
                messages=mensagens,
                temperature=0.25,
                max_tokens=3000,
            )

            texto = resposta.choices[0].message.content.strip()

            # ======================================================
            # üîé BLOCO DE DIAGN√ìSTICO (LOGS STREAMLIT)
            # ======================================================
            try:
                print("===== IA DEBUG START =====")
                print(f"[Modelo] {self.model} | [Artefato] {artefato}")
                print(f"[Conte√∫do] tamanho_total={len(conteudo)} | trecho_enviado={len(trecho_documento)}")
                print("----- PROMPT (in√≠cio) -----")
                print(prompt[:1000])
                print("----- DOCUMENTO (in√≠cio) -----")
                print(trecho_documento[:1000])
                print("----- RESPOSTA BRUTA (in√≠cio) -----")
                print(texto[:2000])
                print("===== IA DEBUG END =====")
            except Exception as log_err:
                print(f"[IA DEBUG] Falha ao imprimir diagn√≥stico: {log_err}")

            # ======================================================
            # Tentativa de convers√£o direta para JSON
            # ======================================================
            try:
                parsed = json.loads(texto)
                print("[IA DEBUG] json.loads(texto) OK (resposta j√° era JSON).")
                return parsed

            except Exception:
                print("[IA DEBUG] json.loads(texto) FALHOU ‚Äì tentando limpar blocos ```json ... ```.")

                # Limpando formata√ß√£o de c√≥digo se vier com blocos
                if texto.startswith("```"):
                    texto_limpo = texto.replace("```json", "").replace("```", "").strip()
                else:
                    texto_limpo = texto

                try:
                    parsed = json.loads(texto_limpo)
                    print("[IA DEBUG] json.loads(texto_limpo) OK ap√≥s limpeza.")
                    return parsed
                except Exception:
                    print("[IA DEBUG] Falha final ao interpretar JSON ‚Äì devolvendo texto cru em 'resposta_texto'.")
                    return {"resposta_texto": texto}

        except Exception as e:
            print(f"[IA DEBUG] EXCE√á√ÉO NA CHAMADA OPENAI: {e}")
            return {
                "erro": f"‚ùå Falha na chamada OpenAI: {e}",
                "modelo_utilizado": self.model,
            }
