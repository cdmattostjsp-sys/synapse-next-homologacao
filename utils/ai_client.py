# ==========================================================
# utils/ai_client.py
# SynapseNext ‚Äì Cliente Institucional OpenAI (TJSP)
# Revis√£o: Engenheiro Synapse ‚Äì 2025-11-08 (vNext_r2)
# Compatibilidade: Streamlit 1.39.0 + openai 2.7.1
# ==========================================================

import os
import json
from openai import OpenAI


class AIClient:
    """
    Cliente institucional padronizado para uso interno dos agentes IA.
    Implementa controle de modelo, chave segura e tratamento de exce√ß√µes.
    """

    def __init__(self, model: str = None):
        """
        Inicializa o cliente OpenAI institucional.

        Args:
            model (str, opcional): modelo a ser usado (ex.: "gpt-4o-mini").
                                   Se n√£o informado, usa o modelo padr√£o
                                   configurado via vari√°vel de ambiente.
        """
        # Obt√©m chave da OpenAI (Streamlit secrets ou ambiente)
        api_key = os.getenv("OPENAI_API_KEY")
        if not api_key:
            raise ValueError("‚ùå OPENAI_API_KEY n√£o encontrada em ambiente (.env ou secrets.toml).")

        # Inicializa cliente OpenAI
        self.client = OpenAI(api_key=api_key)

        # Modelo padr√£o (configur√°vel)
        self.model = model or os.getenv("OPENAI_MODEL", "gpt-4o-mini")

    # ==========================================================
    # M√©todo principal de infer√™ncia textual
    # ==========================================================
    def ask(self, prompt: str, conteudo: str | bytes = "", artefato: str = "DFD") -> dict:
        """
        Envia um prompt para o modelo de linguagem institucional e retorna a resposta.

        Args:
            prompt (str): instru√ß√£o textual principal (pergunta ou template).
            conteudo (str | bytes): corpo do texto do documento analisado.
            artefato (str): tipo de artefato (DFD, ETP, TR, Edital...).

        Returns:
            dict: resposta estruturada em JSON (ou texto cru, se falhar).
        """

        try:
            # ======================================================
            # Garantia de tipo de conte√∫do
            # ======================================================
            if isinstance(conteudo, bytes):
                conteudo = conteudo.decode("utf-8", errors="ignore")
            elif not isinstance(conteudo, str):
                conteudo = str(conteudo)

            # ======================================================
            # Montagem da mensagem de prompt contextualizada
            # ======================================================
            mensagem = (
                f"{prompt}\n\n"
                f"---\n"
                f"üìÑ Conte√∫do do documento (trecho inicial):\n{conteudo[:4000]}\n"
                f"---\n"
                f"Responda no formato JSON estruturado para o artefato institucional: {artefato}."
            )

            # ======================================================
            # Chamada ao modelo OpenAI (chat.completions)
            # ======================================================
            resposta = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {
                        "role": "system",
                        "content": (
                            "Voc√™ √© um assistente t√©cnico institucional do Tribunal de Justi√ßa de S√£o Paulo (TJSP). "
                            "Analise documentos administrativos e gere respostas estruturadas e compat√≠veis "
                            "com os modelos oficiais (DFD, ETP, TR, Edital, Contrato)."
                        ),
                    },
                    {"role": "user", "content": mensagem},
                ],
                temperature=0.4,
                max_tokens=2000,
            )

            # ======================================================
            # Processamento da resposta
            # ======================================================
            texto = resposta.choices[0].message.content.strip()

            # Tenta converter para JSON direto
            try:
                return json.loads(texto)
            except Exception:
                # Retorna texto cru caso a IA n√£o respeite o formato JSON
                return {"resposta_texto": texto}

        # ======================================================
        # Tratamento de falhas de comunica√ß√£o ou execu√ß√£o
        # ======================================================
        except Exception as e:
            return {
                "erro": f"‚ùå Falha na chamada OpenAI: {e}",
                "modelo_utilizado": self.model,
            }
