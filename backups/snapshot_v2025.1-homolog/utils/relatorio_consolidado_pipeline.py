# utils/relatorio_consolidado_pipeline.py
# ==========================================================
# SynapseNext ‚Äì Fase Bras√≠lia (Passo 10C ‚Äì Relat√≥rio T√©cnico Consolidado)
# Consolida: Auditoria.IA + Valida√ß√£o Sem√¢ntica + Comparador.IA
# Gera um .docx institucional com capa/cabe√ßalho via formatter_docx
# ==========================================================

from __future__ import annotations
from pathlib import Path
from datetime import datetime
from typing import Dict, Any, Optional, List
import json
import os

# Imports internos (sem depender de Streamlit aqui)
# Ajuste de path relativo ao projeto
def _root() -> Path:
    return Path(__file__).resolve().parents[1]

# --- Importa utilit√°rios existentes ---
try:
    from utils.comparador_pipeline import carregar_snapshots, analisar_coerencia
except Exception:
    # Carregamento tardio, se necess√°rio
    import sys
    sys.path.append(str(_root()))
    from utils.comparador_pipeline import carregar_snapshots, analisar_coerencia  # type: ignore

try:
    from utils.auditoria_pipeline import read_last_audit
except Exception:
    import sys
    sys.path.append(str(_root()))
    from utils.auditoria_pipeline import read_last_audit  # type: ignore

try:
    from utils.next_pipeline import run_semantic_validation
except Exception:
    import sys
    sys.path.append(str(_root()))
    from utils.next_pipeline import run_semantic_validation  # type: ignore

try:
    from utils.formatter_docx import markdown_to_docx
except Exception:
    import sys
    sys.path.append(str(_root()))
    from utils.formatter_docx import markdown_to_docx  # type: ignore


# ----------------------------------------------------------
# Diret√≥rios de sa√≠da
# ----------------------------------------------------------
def _ensure_dirs() -> Dict[str, Path]:
    base = _root()
    out = {
        "analises": base / "exports" / "analises",
        "relatorios": base / "exports" / "relatorios",
    }
    for p in out.values():
        p.mkdir(parents=True, exist_ok=True)
    return out


# ----------------------------------------------------------
# Coleta integral dos dados (auditoria + coer√™ncia + IA)
# ----------------------------------------------------------
def coletar_dados_relatorio() -> Dict[str, Any]:
    """
    Coleta os dados necess√°rios ao relat√≥rio consolidado:
    - Snapshots mais recentes (DFD, ETP, TR, Edital)
    - Auditoria (hash, snapshot_relpath, word_count)
    - Valida√ß√£o sem√¢ntica (resumo, pontua√ß√£o, sugest√µes) executada agora
    - Comparador.IA (coer√™ncia global e diverg√™ncias)
    """
    artefatos_md = carregar_snapshots(recente=True)  # textos limpos
    artefatos_ordem = ["DFD", "ETP", "TR", "Edital"]

    # Auditoria por artefato (√∫ltimo do dia corrente)
    auditoria: Dict[str, Any] = {}
    for art in artefatos_ordem:
        auditoria[art] = read_last_audit(art) or {}

    # Valida√ß√£o IA por artefato (se houver texto)
    validacoes: Dict[str, Any] = {}
    for art, text in artefatos_md.items():
        try:
            validacoes[art] = run_semantic_validation(text)
        except Exception as e:
            validacoes[art] = {"erro": str(e), "resumo": "", "pontuacao": 0, "sugestoes": []}

    # Comparador.IA
    coerencia = analisar_coerencia(artefatos_md) if artefatos_md else {
        "coerencia_global": 0,
        "comparacoes": {},
        "divergencias": [{"campo": "geral", "descricao": "N√£o h√° snapshots auditados suficientes."}],
        "ausencias": []
    }

    return {
        "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        "artefatos_texto": artefatos_md,
        "auditoria": auditoria,
        "validacoes": validacoes,
        "coerencia": coerencia,
        "ordem": artefatos_ordem,
    }


# ----------------------------------------------------------
# Constru√ß√£o do Markdown institucional do relat√≥rio
# ----------------------------------------------------------
def _mk_section_validacao(nome: str, val: Dict[str, Any]) -> List[str]:
    linhas = [f"### üìÑ {nome} ‚Äî Valida√ß√£o Sem√¢ntica"]
    if val.get("erro"):
        linhas.append(f"- ‚ö†Ô∏è **Erro**: {val.get('erro')}")
        return linhas
    resumo = val.get("resumo", "")
    pontos = val.get("pontuacao", 0)
    linhas.append(f"- **Resumo:** {resumo}")
    linhas.append(f"- **Pontua√ß√£o de completude:** **{pontos}%**")
    sugestoes = val.get("sugestoes", [])
    if sugestoes:
        linhas.append("- **Sugest√µes de melhoria:**")
        for s in sugestoes:
            linhas.append(f"  - {s}")
    return linhas


def _mk_section_auditoria(nome: str, aud: Dict[str, Any]) -> List[str]:
    linhas = [f"### üîê {nome} ‚Äî Auditoria Digital"]
    if not aud:
        linhas.append("- ‚ùå Sem registro de auditoria para o dia corrente.")
        return linhas
    short_hash = aud.get("sha256", "")[:10] if aud.get("sha256") else "‚Äî"
    linhas.append(f"- **Hash (SHA-256):** `{short_hash}`")
    linhas.append(f"- **Palavras (word_count):** {aud.get('word_count', 0)}")
    snap_rel = aud.get("snapshot_relpath", "‚Äî")
    linhas.append(f"- **Snapshot:** `{snap_rel}`")
    return linhas


def _mk_section_coerencia(coe: Dict[str, Any]) -> List[str]:
    linhas = ["## üß© Coer√™ncia Global (Comparador.IA)"]
    linhas.append(f"- **Coer√™ncia Global:** **{coe.get('coerencia_global', 0)}%**")
    if coe.get("comparacoes"):
        linhas.append("\n### üîé Compara√ß√µes diretas")
        for par, val in coe["comparacoes"].items():
            linhas.append(f"- **{par}** ‚Üí Similaridade: `{val}%`")
    if coe.get("divergencias"):
        linhas.append("\n### ‚ö†Ô∏è Diverg√™ncias")
        for d in coe["divergencias"]:
            linhas.append(f"- {d.get('descricao', '')}")
    if coe.get("ausencias"):
        linhas.append("\n### ‚ùå Aus√™ncias")
        for a in coe["ausencias"]:
            linhas.append(f"- {a.get('descricao', '')}")
    return linhas


def _construir_markdown(dados: Dict[str, Any]) -> str:
    linhas: List[str] = []
    linhas.append("# üìò Relat√≥rio T√©cnico Consolidado ‚Äî Fase Interna (SynapseNext)")
    linhas.append(f"**Data de gera√ß√£o:** {dados.get('timestamp', '')}")
    linhas.append("")
    linhas.append("Este relat√≥rio consolida as evid√™ncias t√©cnicas do SynapseNext (Fase Bras√≠lia), abrangendo:")
    linhas.append("- Auditoria Digital (hash, snapshots e m√©tricas)")
    linhas.append("- Valida√ß√£o Sem√¢ntica por IA (resumo, pontua√ß√£o e sugest√µes)")
    linhas.append("- An√°lise de Coer√™ncia entre artefatos (Comparador.IA)")
    linhas.append("---\n")

    # Se√ß√µes por artefato na ordem institucional
    ordem = dados.get("ordem", ["DFD", "ETP", "TR", "Edital"])
    validacoes = dados.get("validacoes", {})
    auditoria = dados.get("auditoria", {})

    for nome in ordem:
        linhas.append(f"## {nome}")
        linhas += _mk_section_auditoria(nome, auditoria.get(nome, {}))
        linhas.append("")
        linhas += _mk_section_validacao(nome, validacoes.get(nome, {}))
        linhas.append("\n---\n")

    # Coer√™ncia global
    linhas += _mk_section_coerencia(dados.get("coerencia", {}))
    linhas.append("\n---\n")
    linhas.append("_Relat√≥rio gerado automaticamente pelo SynapseNext ‚Äî SAAB 5.0 / TJSP (Fase Bras√≠lia)._")

    return "\n".join(linhas)


# ----------------------------------------------------------
# Gera√ß√£o do DOCX institucional
# ----------------------------------------------------------
def gerar_relatorio_docx(dados: Dict[str, Any]) -> str:
    """
    Constr√≥i o markdown do relat√≥rio consolidado e gera um .docx institucional
    usando utils.formatter_docx.markdown_to_docx. Retorna o caminho do arquivo.
    """
    out_dirs = _ensure_dirs()
    md_text = _construir_markdown(dados)

    # Caminho de sa√≠da
    fname = f"Relatorio_Tecnico_{datetime.now().strftime('%Y%m%d_%H%M%S')}.docx"
    out_path = out_dirs["relatorios"] / fname

    # Gera DOCX com capa/cabe√ßalho institucional
    markdown_to_docx(md_text, str(out_path), artefato_nome="Relat√≥rio T√©cnico Consolidado")

    return str(out_path)
