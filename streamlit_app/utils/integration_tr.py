# -*- coding: utf-8 -*-
"""
streamlit_app/utils/integration_tr.py ‚Äì Exporta√ß√£o/Importa√ß√£o do TR
Respons√°vel por:
- Gravar o arquivo exports/tr_data.json a partir dos metadados do TR.
- Ler o arquivo exports/tr_data.json para pr√©-preencher o m√≥dulo Contrato.
- Processar insumos (PDF, DOCX, TXT) usando IA institucional para extrair campos do TR.
"""

import json
import os
import re
from typing import Dict, Any
from pathlib import Path

# ‚ö†Ô∏è IMPORT CORRIGIDO:
# o ai_client est√° na pasta raiz utils/, n√£o em streamlit_app/utils/
try:
    from utils.ai_client import AIClient
except Exception:
    AIClient = None

# ==========================================================
# üìÇ Diret√≥rios e caminhos de exporta√ß√£o
# ==========================================================
# Este caminho aponta para: /workspaces/synapse-next/streamlit_app/exports/tr_data.json
EXPORTS_DIR = os.path.join(os.path.dirname(os.path.dirname(__file__)), "exports")
TR_JSON_PATH = os.path.join(EXPORTS_DIR, "tr_data.json")

# Cliente de IA institucional (opcional ‚Äì se falhar, continuamos sem IA)
client = None
if AIClient is not None:
    try:
        client = AIClient()
    except Exception:
        client = None


# ==========================================================
# üì§ Utilit√°rios de exporta√ß√£o
# ==========================================================
def ensure_exports_dir(path: str = EXPORTS_DIR) -> None:
    os.makedirs(path, exist_ok=True)


def export_tr_to_json(data: Dict[str, Any], path: str = TR_JSON_PATH) -> str:
    """Exporta os metadados do TR para JSON, usado por outros m√≥dulos (ex.: Contrato)."""
    ensure_exports_dir(os.path.dirname(path))
    with open(path, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)
    return path


def load_tr_from_json(path: str = TR_JSON_PATH) -> Dict[str, Any]:
    """Carrega o √∫ltimo TR exportado para reaproveitamento."""
    try:
        if os.path.exists(path):
            with open(path, "r", encoding="utf-8") as f:
                return json.load(f)
    except Exception:
        pass
    return {}


# ==========================================================
# üß† Base de conhecimento institucional (Knowledge Base)
# ==========================================================
def ler_modelos_tr() -> str:
    """
    L√™ os modelos textuais de TR.
    Na sua √°rvore atual n√£o h√° exatamente 'knowledge/tr_models', ent√£o buscamos em:
    - knowledge/tr_models
    - knowledge/TR
    - knowledge_base/TR
    Devolvemos um √∫nico texto concatenado.
    """
    textos = []

    base_dir = Path(__file__).resolve().parents[1]

    candidatos = [
        base_dir / "knowledge" / "tr_models",
        base_dir / "knowledge" / "TR",
        base_dir / "knowledge_base" / "TR",
    ]

    for base in candidatos:
        if base.exists() and base.is_dir():
            for arq in base.glob("*.txt"):
                try:
                    textos.append(arq.read_text(encoding="utf-8"))
                except Exception:
                    pass

    return "\n\n".join(textos)


# ==========================================================
# ü§ñ Processamento de Insumo ‚Äì IA Institucional TR
# ==========================================================
def processar_insumo_tr(arquivo, artefato: str = "TR") -> dict:
    """
    Extrai o texto do arquivo enviado (PDF, DOCX ou TXT),
    realiza an√°lise sem√¢ntica e retorna campos padronizados do TR.

    Retorno padr√£o:
    {
        "artefato": "TR",
        "nome_arquivo": "...",
        "status": "processado",
        "campos_ai": { ... }
    }
    """
    from io import BytesIO

    # depend√™ncias de leitura ‚Äì est√£o sendo usadas em outros pontos do projeto
    import fitz
    import docx2txt

    dados = arquivo.read()
    arquivo.seek(0)
    nome = arquivo.name.lower()
    texto_extraido = ""

    # 1Ô∏è‚É£ Extra√ß√£o de texto do insumo
    try:
        if nome.endswith(".pdf"):
            pdf = fitz.open(stream=dados, filetype="pdf")
            texto_extraido = "".join(p.get_text() for p in pdf)
        elif nome.endswith(".docx"):
            texto_extraido = docx2txt.process(BytesIO(dados))
        elif nome.endswith(".txt"):
            texto_extraido = dados.decode("utf-8", errors="ignore")
    except Exception as e:
        return {"erro": f"Falha ao extrair texto: {e}"}

    if not texto_extraido.strip():
        return {"erro": "Texto vazio ap√≥s leitura do insumo."}

    texto_limpo = re.sub(r"\s+", " ", texto_extraido).strip()
    modelos = ler_modelos_tr()

    # Se n√£o temos cliente de IA dispon√≠vel, devolvemos um fallback
    if client is None:
        # normaliza√ß√£o m√≠nima para a p√°gina TR
        campos_ai = {
            "objeto": texto_limpo[:500],
            "justificativa_tecnica": "Conte√∫do extra√≠do do insumo. Refine com a IA quando dispon√≠vel.",
            "especificacao_tecnica": "",
            "criterios_julgamento": "",
            "riscos": "Sem riscos adicionais identificados.",
            "observacoes_finais": "",
            "prazo_execucao": "",
            "estimativa_valor": "",
            "fonte_recurso": "",
        }
        for k, v in campos_ai.items():
            if not v:
                campos_ai[k] = "‚Äî"
        return {
            "artefato": artefato,
            "nome_arquivo": arquivo.name,
            "status": "processado_sem_ia",
            "campos_ai": campos_ai,
        }

    # 2Ô∏è‚É£ Prompt institucional para IA
    system_prompt = (
        "Voc√™ √© um agente institucional do Tribunal de Justi√ßa de S√£o Paulo, especializado em Termos de Refer√™ncia (TR). "
        "Analise o texto do insumo e extraia os campos padronizados conforme os modelos institucionais do TJSP."
    )

    user_prompt = f"""
Texto do insumo:
\"\"\"{texto_limpo}\"\"\"


Modelos de refer√™ncia:
\"\"\"{modelos}\"\"\"


Retorne apenas um JSON com os seguintes campos:
- objeto
- justificativa
- especificacoes_tecnicas
- criterios_de_julgamento
- obrigacoes_da_contratada
- prazo_execucao
- estimativa_valor
- fonte_recurso
"""

    # 3Ô∏è‚É£ Chamada √† IA institucional
    try:
        response = client.chat(
            [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt},
            ]
        )
        conteudo = response["content"]
        match = re.search(r"\{.*\}", conteudo, re.DOTALL)
        campos = json.loads(match.group(0)) if match else {"objeto": texto_limpo[:800]}
    except Exception as e:
        campos = {"erro": f"Falha ao processar IA: {e}"}

    # ==========================================================
    # üîÑ Normaliza√ß√£o de campos para compatibilidade com a p√°gina TR
    # ==========================================================
    campos_ai = {
        "objeto": campos.get("objeto", ""),
        "justificativa_tecnica": campos.get("justificativa", ""),
        "especificacao_tecnica": campos.get("especificacoes_tecnicas", ""),
        "criterios_julgamento": campos.get("criterios_de_julgamento", ""),
        "riscos": campos.get("obrigacoes_da_contratada", "Sem riscos adicionais identificados."),
        "observacoes_finais": "",
        "prazo_execucao": campos.get("prazo_execucao", ""),
        "estimativa_valor": campos.get("estimativa_valor", ""),
        "fonte_recurso": campos.get("fonte_recurso", ""),
    }

    # Fallback seguro ‚Äì garante que nenhum campo fique vazio
    for k, v in campos_ai.items():
        if not v:
            campos_ai[k] = "‚Äî"

    print(f"[IA:TR] Arquivo: {arquivo.name} ‚Äì Campos normalizados: {list(campos_ai.keys())}")

    # ==========================================================
    # üì¶ Retorno final compat√≠vel com o SynapseNext
    # ==========================================================
    return {
        "artefato": artefato,
        "nome_arquivo": arquivo.name,
        "status": "processado",
        "campos_ai": campos_ai,
    }
